{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Fine Food Reviews Analysis using pyspark\n",
    "\n",
    "The Amazon Fine Food Reviews dataset consists of reviews of fine foods from Amazon.<br>\n",
    "\n",
    "Number of reviews: 50,000<br>\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "\n",
    "1. Text - text of the review\n",
    "2. Score - positive/negative\n",
    "\n",
    "\n",
    "#### Objective:\n",
    "\n",
    "<br>\n",
    "[Q] How to determine if a review is positive or negative?<br>\n",
    "<br> \n",
    "[Ans] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.64.11.191:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc34199e160>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark \n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"NLP\").getOrCreate()\n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml import Pipeline # For pipeline development\n",
    "from pyspark.ml.feature import * #CountVectorizer,StringIndexer, RegexTokenizer,StopWordsRemover\n",
    "from pyspark.sql.functions import * #col, udf,regexp_replace,isnull\n",
    "from pyspark.sql.types import * #StringType,IntegerType\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV\n",
    "df = spark.read.csv('amazon_rev.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n",
      "|Text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |Score   |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n",
      "|I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |positive|\n",
      "|Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as Jumbo.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |negative|\n",
      "|This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis' The Lion, The Witch, and The Wardrobe - this is the treat that seduces Edmund into selling out his Brother and Sisters to                                                                                                                                                                                                                                                                                           |positive|\n",
      "|If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The flavor is very medicinal.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |negative|\n",
      "|Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |positive|\n",
      "|I got a wild hair for taffy and ordered this five pound bag. The taffy was all very enjoyable with many flavors: watermelon, root beer, melon, peppermint, grape, etc. My only complaint is there was a bit too much red/black licorice-flavored pieces (just not my particular favorites). Between me, my kids, and my husband, this lasted only two weeks! I would recommend this brand of taffy -- it was a delightful treat.                                                                                                                                                                                                                                                                                                                                                                           |positive|\n",
      "|This saltwater taffy had great flavors and was very soft and chewy.  Each candy was individually wrapped well.  None of the candies were stuck together, which did happen in the expensive version, Fralinger's.  Would highly recommend this candy!  I served it at a beach-themed party and everyone loved it!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |positive|\n",
      "|This taffy is so good.  It is very soft and chewy.  The flavors are amazing.  I would definitely recommend you buying it.  Very satisfying!!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |positive|\n",
      "|Right now I'm mostly just sprouting this so my cats can eat the grass. They love it. I rotate it around with Wheatgrass and Rye too                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |positive|\n",
      "|This is a very healthy dog food. Good for their digestion. Also good for small puppies. My dog eats her required amount at every feeding.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |positive|\n",
      "|I don't know if it's the cactus or the tequila or just the unique combination of ingredients, but the flavour of this hot sauce makes it one of a kind!  We picked up a bottle once on a trip we were on and brought it back home with us and were totally blown away!  When we realized that we simply couldn't find it anywhere in our city we were bummed.<br /><br />Now, because of the magic of the internet, we have a case of the sauce and are ecstatic because of it.<br /><br />If you love hot sauce..I mean really love hot sauce, but don't want a sauce that tastelessly burns your throat, grab a bottle of Tequila Picante Gourmet de Inclan.  Just realize that once you taste it, you will never want to use any other sauce.<br /><br />Thank you for the personal, incredible service!|positive|\n",
      "|One of my boys needed to lose some weight and the other didn't.  I put this food on the floor for the chubby guy, and the protein-rich, no by-product food up higher where only my skinny boy can jump.  The higher food sits going stale.  They both really go for this food.  And my chubby boy has been losing about an ounce a week.                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |positive|\n",
      "|My cats have been happily eating Felidae Platinum for more than two years. I just got a new bag and the shape of the food is different. They tried the new food when I first put it in their bowls and now the bowls sit full and the kitties will not touch the food. I've noticed similar reviews related to formula changes in the past. Unfortunately, I now need to find a new food that my cats will eat.                                                                                                                                                                                                                                                                                                                                                                                            |negative|\n",
      "|good flavor! these came securely packed... they were fresh and delicious! i love these Twizzlers!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |positive|\n",
      "|The Strawberry Twizzlers are my guilty pleasure - yummy. Six pounds will be around for a while with my son and I.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |positive|\n",
      "|My daughter loves twizzlers and this shipment of six pounds really hit the spot. It's exactly what you would expect...six packages of strawberry twizzlers.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |positive|\n",
      "|I love eating them and they are good for watching TV and looking at movies! It is not too sweet. I like to transfer them to a zip lock baggie so they stay fresh so I can take my time eating them.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |negative|\n",
      "|I am very satisfied with my Twizzler purchase.  I shared these with others and we have all enjoyed them.  I will definitely be ordering more.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |positive|\n",
      "|Twizzlers, Strawberry my childhood favorite candy, made in Lancaster Pennsylvania by Y & S Candies, Inc. one of the oldest confectionery Firms in the United States, now a Subsidiary of the Hershey Company, the Company was established in 1845 as Young and Smylie, they also make Apple Licorice Twists, Green Color and Blue Raspberry Licorice Twists, I like them all<br /><br />I keep it in a dry cool place because is not recommended it to put it in the fridge. According to the Guinness Book of Records, the longest Licorice Twist ever made measured 1.200 Feet (370 M) and weighted 100 Pounds (45 Kg) and was made by Y & S Candies, Inc. This Record-Breaking Twist became a Guinness World Record on July 19, 1998. This Product is Kosher! Thank You                                 |positive|\n",
      "|Candy was delivered very fast and was purchased at a reasonable price.  I was home bound and unable to get to a store so this was perfect for me.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |positive|\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's read a few full blurbs\n",
    "df.show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text     Score\n",
       "0  I have bought several of the Vitality canned d...  positive\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...  negative\n",
       "2  This is a confection that has been around a fe...  positive\n",
       "3  If you are looking for the secret ingredient i...  negative\n",
       "4  Great taffy at a great price.  There was a wid...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Text: string (nullable = true)\n",
      " |-- Score: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many null values do we have?\n",
    "\n",
    "Let's use our handy dandy function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows that contain at least one null value: 1\n",
      "Percentage of Rows that contain at least one null value: 2e-05\n"
     ]
    }
   ],
   "source": [
    "# Of course you will want to know how many rows that affected before you actually execute it..\n",
    "og_len = df.count()\n",
    "drop_len = df.na.drop().count()\n",
    "print(\"Total Rows that contain at least one null value:\",og_len-drop_len)\n",
    "print(\"Percentage of Rows that contain at least one null value:\", (og_len-drop_len)/og_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49999"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>41788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>8211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Score  count\n",
       "0  positive  41788\n",
       "1  negative   8211"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick data quality check on the state column....\n",
    "# This is going to be our category column so it's important\n",
    "df.groupBy(\"Score\").count().orderBy(col(\"count\").desc()).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.                                                                                                                                                                                                                                          |\n",
      "|Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as Jumbo.                                                                                                                                                                                                                                                                                                                     |\n",
      "|This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis' The Lion, The Witch, and The Wardrobe - this is the treat that seduces Edmund into selling out his Brother and Sisters to |\n",
      "|If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The flavor is very medicinal.                                                                                                                                                                                                                                                                                      |\n",
      "|Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "|I got a wild hair for taffy and ordered this five pound bag. The taffy was all very enjoyable with many flavors: watermelon, root beer, melon, peppermint, grape, etc. My only complaint is there was a bit too much red/black licorice-flavored pieces (just not my particular favorites). Between me, my kids, and my husband, this lasted only two weeks! I would recommend this brand of taffy -- it was a delightful treat.                                                                                 |\n",
      "|This saltwater taffy had great flavors and was very soft and chewy.  Each candy was individually wrapped well.  None of the candies were stuck together, which did happen in the expensive version, Fralinger's.  Would highly recommend this candy!  I served it at a beach-themed party and everyone loved it!                                                                                                                                                                                                 |\n",
      "|This taffy is so good.  It is very soft and chewy.  The flavors are amazing.  I would definitely recommend you buying it.  Very satisfying!!                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "|Right now I'm mostly just sprouting this so my cats can eat the grass. They love it. I rotate it around with Wheatgrass and Rye too                                                                                                                                                                                                                                                                                                                                                                              |\n",
      "|This is a very healthy dog food. Good for their digestion. Also good for small puppies. My dog eats her required amount at every feeding.                                                                                                                                                                                                                                                                                                                                                                        |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check the quality of the blurbs\n",
    "df.select(\"Text\").show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the Text column\n",
    "\n",
    "Keep in mind that you can/should do all of this in one call...\n",
    "But we will show each individually for the purpose of learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.                                                                                                                                                                                                                                          |\n",
      "|Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as Jumbo.                                                                                                                                                                                                                                                                                                                     |\n",
      "|This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis' The Lion, The Witch, and The Wardrobe - this is the treat that seduces Edmund into selling out his Brother and Sisters to |\n",
      "|If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered  which was good  and made some cherry soda.  The flavor is very medicinal.                                                                                                                                                                                                                                                                                      |\n",
      "|Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "|I got a wild hair for taffy and ordered this five pound bag. The taffy was all very enjoyable with many flavors: watermelon, root beer, melon, peppermint, grape, etc. My only complaint is there was a bit too much red black licorice-flavored pieces  just not my particular favorites . Between me, my kids, and my husband, this lasted only two weeks! I would recommend this brand of taffy -- it was a delightful treat.                                                                                 |\n",
      "|This saltwater taffy had great flavors and was very soft and chewy.  Each candy was individually wrapped well.  None of the candies were stuck together, which did happen in the expensive version, Fralinger's.  Would highly recommend this candy!  I served it at a beach-themed party and everyone loved it!                                                                                                                                                                                                 |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"Text\",translate(col(\"Text\"), \"/\", \" \")) \\\n",
    "        .withColumn(\"Text\",translate(col(\"Text\"), \"(\", \" \")) \\\n",
    "        .withColumn(\"Text\",translate(col(\"Text\"), \")\", \" \"))\n",
    "df.select(\"Text\").show(7,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|I have bought several of the Vitality canned dog food products and have found them all to be of good quality The product looks more like a stew than a processed meat and it smells better My Labrador is finicky and she appreciates this product better than  most                                                                                                                                                                                                                              |\n",
      "|Product arrived labeled as Jumbo Salted Peanutsthe peanuts were actually small sized unsalted Not sure if this was an error or if the vendor intended to represent the product as Jumbo                                                                                                                                                                                                                                                                                                           |\n",
      "|This is a confection that has been around a few centuries  It is a light pillowy citrus gelatin with nuts  in this case Filberts And it is cut into tiny squares and then liberally coated with powdered sugar  And it is a tiny mouthful of heaven  Not too chewy and very flavorful  I highly recommend this yummy treat  If you are familiar with the story of CS Lewis The Lion The Witch and The Wardrobe  this is the treat that seduces Edmund into selling out his Brother and Sisters to |\n",
      "|If you are looking for the secret ingredient in Robitussin I believe I have found it  I got this in addition to the Root Beer Extract I ordered  which was good  and made some cherry soda  The flavor is very medicinal                                                                                                                                                                                                                                                                          |\n",
      "|Great taffy at a great price  There was a wide assortment of yummy taffy  Delivery was very quick  If your a taffy lover this is a deal                                                                                                                                                                                                                                                                                                                                                           |\n",
      "|I got a wild hair for taffy and ordered this five pound bag The taffy was all very enjoyable with many flavors watermelon root beer melon peppermint grape etc My only complaint is there was a bit too much red black licoriceflavored pieces  just not my particular favorites  Between me my kids and my husband this lasted only two weeks I would recommend this brand of taffy  it was a delightful treat                                                                                   |\n",
      "|This saltwater taffy had great flavors and was very soft and chewy  Each candy was individually wrapped well  None of the candies were stuck together which did happen in the expensive version Fralingers  Would highly recommend this candy  I served it at a beachthemed party and everyone loved it                                                                                                                                                                                           |\n",
      "|This taffy is so good  It is very soft and chewy  The flavors are amazing  I would definitely recommend you buying it  Very satisfying                                                                                                                                                                                                                                                                                                                                                            |\n",
      "|Right now Im mostly just sprouting this so my cats can eat the grass They love it I rotate it around with Wheatgrass and Rye too                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|This is a very healthy dog food Good for their digestion Also good for small puppies My dog eats her required amount at every feeding                                                                                                                                                                                                                                                                                                                                                             |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Removing anything that is not a letter\n",
    "df = df.withColumn(\"Text\",regexp_replace(col('Text'), '[^A-Za-z ]+', ''))\n",
    "df.select(\"Text\").show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|I have bought several of the Vitality canned dog food products and have found them all to be of good quality The product looks more like a stew than a processed meat and it smells better My Labrador is finicky and she appreciates this product better than most                                                                                                                                                                                                                        |\n",
      "|Product arrived labeled as Jumbo Salted Peanutsthe peanuts were actually small sized unsalted Not sure if this was an error or if the vendor intended to represent the product as Jumbo                                                                                                                                                                                                                                                                                                    |\n",
      "|This is a confection that has been around a few centuries It is a light pillowy citrus gelatin with nuts in this case Filberts And it is cut into tiny squares and then liberally coated with powdered sugar And it is a tiny mouthful of heaven Not too chewy and very flavorful I highly recommend this yummy treat If you are familiar with the story of CS Lewis The Lion The Witch and The Wardrobe this is the treat that seduces Edmund into selling out his Brother and Sisters to |\n",
      "|If you are looking for the secret ingredient in Robitussin I believe I have found it I got this in addition to the Root Beer Extract I ordered which was good and made some cherry soda The flavor is very medicinal                                                                                                                                                                                                                                                                       |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove multiple spaces\n",
    "df = df.withColumn(\"Text\",regexp_replace(col('Text'), ' +', ' '))\n",
    "df.select(\"Text\").show(4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|i have bought several of the vitality canned dog food products and have found them all to be of good quality the product looks more like a stew than a processed meat and it smells better my labrador is finicky and she appreciates this product better than most                                                                                                                                                                                                                        |\n",
      "|product arrived labeled as jumbo salted peanutsthe peanuts were actually small sized unsalted not sure if this was an error or if the vendor intended to represent the product as jumbo                                                                                                                                                                                                                                                                                                    |\n",
      "|this is a confection that has been around a few centuries it is a light pillowy citrus gelatin with nuts in this case filberts and it is cut into tiny squares and then liberally coated with powdered sugar and it is a tiny mouthful of heaven not too chewy and very flavorful i highly recommend this yummy treat if you are familiar with the story of cs lewis the lion the witch and the wardrobe this is the treat that seduces edmund into selling out his brother and sisters to |\n",
      "|if you are looking for the secret ingredient in robitussin i believe i have found it i got this in addition to the root beer extract i ordered which was good and made some cherry soda the flavor is very medicinal                                                                                                                                                                                                                                                                       |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lower case everything\n",
    "df = df.withColumn(\"Text\",lower(col('Text')))\n",
    "df.select(\"Text\").show(4,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Data for NLP \n",
    "\n",
    "Alright so here is where our analysis turns from basic text cleaning to actually turning our text into number (the backbone of NLP). These next several steps in our analysis are very unique to NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split text into words (Tokenizing)\n",
    "\n",
    "Yo'll see a new column is added to our dataframe that we call \"words\". This column contains an array of strings as opposed to just a string (current data type of the blurb column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Text                                                                                                                                                                                                                                                               |Score   |words                                                                                                                                                                                                                                                                                                               |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|i have bought several of the vitality canned dog food products and have found them all to be of good quality the product looks more like a stew than a processed meat and it smells better my labrador is finicky and she appreciates this product better than most|positive|[i, have, bought, several, of, the, vitality, canned, dog, food, products, and, have, found, them, all, to, be, of, good, quality, the, product, looks, more, like, a, stew, than, a, processed, meat, and, it, smells, better, my, labrador, is, finicky, and, she, appreciates, this, product, better, than, most]|\n",
      "|product arrived labeled as jumbo salted peanutsthe peanuts were actually small sized unsalted not sure if this was an error or if the vendor intended to represent the product as jumbo                                                                            |negative|[product, arrived, labeled, as, jumbo, salted, peanutsthe, peanuts, were, actually, small, sized, unsalted, not, sure, if, this, was, an, error, or, if, the, vendor, intended, to, represent, the, product, as, jumbo]                                                                                             |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "root\n",
      " |-- Text: string (nullable = true)\n",
      " |-- Score: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    regex_tokenizer = RegexTokenizer(inputCol=\"Text\", outputCol=\"words\", pattern=\"\\W\")\n",
    "raw_words = regex_tokenizer.transform(df)\n",
    "raw_words.show(2,False)\n",
    "raw_words.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Stopwords\n",
    "\n",
    "**Recall from the content review lecture**\n",
    "Recall that \"stopwords\" are any word that we feel would \"distract\" our model from performing it's best. This list can be customized, but for now, we will just use the default list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "# Define a list of stop words or use default list\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "stopwords = remover.getStopWords() \n",
    "\n",
    "# Display default list\n",
    "stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Text                                                                                                                                                                                                                                                               |Score   |words                                                                                                                                                                                                                                                                                                               |filtered                                                                                                                                                                                    |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|i have bought several of the vitality canned dog food products and have found them all to be of good quality the product looks more like a stew than a processed meat and it smells better my labrador is finicky and she appreciates this product better than most|positive|[i, have, bought, several, of, the, vitality, canned, dog, food, products, and, have, found, them, all, to, be, of, good, quality, the, product, looks, more, like, a, stew, than, a, processed, meat, and, it, smells, better, my, labrador, is, finicky, and, she, appreciates, this, product, better, than, most]|[bought, several, vitality, canned, dog, food, products, found, good, quality, product, looks, like, stew, processed, meat, smells, better, labrador, finicky, appreciates, product, better]|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_df = remover.transform(raw_words)\n",
    "words_df.show(1,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we need to encode state column to a column of indices\n",
    "\n",
    "Remember that MLlib requres our dependent variable to not only be a numeric data type, but also zero indexed. We can Sparks handy built in StringIndexer function to accomplish this, just like we did in the classification lectures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+--------------------+-----+\n",
      "|                Text|   Score|               words|            filtered|label|\n",
      "+--------------------+--------+--------------------+--------------------+-----+\n",
      "|i have bought sev...|positive|[i, have, bought,...|[bought, several,...|  0.0|\n",
      "|product arrived l...|negative|[product, arrived...|[product, arrived...|  1.0|\n",
      "|this is a confect...|positive|[this, is, a, con...|[confection, arou...|  0.0|\n",
      "|if you are lookin...|negative|[if, you, are, lo...|[looking, secret,...|  1.0|\n",
      "|great taffy at a ...|positive|[great, taffy, at...|[great, taffy, gr...|  0.0|\n",
      "+--------------------+--------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- Text: string (nullable = true)\n",
      " |-- Score: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- filtered: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- label: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCol=\"Score\", outputCol=\"label\")\n",
    "feature_data = indexer.fit(words_df).transform(words_df)\n",
    "feature_data.show(5)\n",
    "feature_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting text into vectors\n",
    "\n",
    "We will test out the following three vectorizors:\n",
    "\n",
    "1. Count Vectors\n",
    "2. TF-IDF\n",
    "3. Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vector (count vectorizer and hashingTF are basically the same thing)\n",
    "# cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\")\n",
    "# model = cv.fit(feature_data)\n",
    "# countVectorizer_features = model.transform(feature_data)\n",
    "\n",
    "# Hashing TF\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawfeatures\", numFeatures=20)\n",
    "HTFfeaturizedData = hashingTF.transform(feature_data)\n",
    "\n",
    "# TF-IDF\n",
    "idf = IDF(inputCol=\"rawfeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(HTFfeaturizedData)\n",
    "TFIDFfeaturizedData = idfModel.transform(HTFfeaturizedData)\n",
    "TFIDFfeaturizedData.name = 'TFIDFfeaturizedData'\n",
    "\n",
    "#rename the HTF features to features to be consistent\n",
    "HTFfeaturizedData = HTFfeaturizedData.withColumnRenamed(\"rawfeatures\",\"features\")\n",
    "HTFfeaturizedData.name = 'HTFfeaturizedData' #We will use later for printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>label</th>\n",
       "      <th>rawfeatures</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i have bought several of the vitality canned d...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[i, have, bought, several, of, the, vitality, ...</td>\n",
       "      <td>[bought, several, vitality, canned, dog, food,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 4.0, 4.0, ...</td>\n",
       "      <td>(0.0, 1.3131902060863196, 0.7708544287433142, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[product, arrived, labeled, as, jumbo, salted,...</td>\n",
       "      <td>[product, arrived, labeled, jumbo, salted, pea...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 2.0, 4.0, 1.0, 2.0, 0.0, 0.0, 4.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.8754601373908798, 1.5417088574866284, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is a confection that has been around a fe...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[this, is, a, confection, that, has, been, aro...</td>\n",
       "      <td>[confection, around, centuries, light, pillowy...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(2.0, 3.0, 5.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, ...</td>\n",
       "      <td>(0.5112818338139713, 1.3131902060863196, 1.927...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you are looking for the secret ingredient i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[if, you, are, looking, for, the, secret, ingr...</td>\n",
       "      <td>[looking, secret, ingredient, robitussin, beli...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>(0.5112818338139713, 0.4377300686954399, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy at a great price there was a wide ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[great, taffy, at, a, great, price, there, was...</td>\n",
       "      <td>[great, taffy, great, price, wide, assortment,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.3824030925114636, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text     Score  \\\n",
       "0  i have bought several of the vitality canned d...  positive   \n",
       "1  product arrived labeled as jumbo salted peanut...  negative   \n",
       "2  this is a confection that has been around a fe...  positive   \n",
       "3  if you are looking for the secret ingredient i...  negative   \n",
       "4  great taffy at a great price there was a wide ...  positive   \n",
       "\n",
       "                                               words  \\\n",
       "0  [i, have, bought, several, of, the, vitality, ...   \n",
       "1  [product, arrived, labeled, as, jumbo, salted,...   \n",
       "2  [this, is, a, confection, that, has, been, aro...   \n",
       "3  [if, you, are, looking, for, the, secret, ingr...   \n",
       "4  [great, taffy, at, a, great, price, there, was...   \n",
       "\n",
       "                                            filtered  label  \\\n",
       "0  [bought, several, vitality, canned, dog, food,...    0.0   \n",
       "1  [product, arrived, labeled, jumbo, salted, pea...    1.0   \n",
       "2  [confection, around, centuries, light, pillowy...    0.0   \n",
       "3  [looking, secret, ingredient, robitussin, beli...    1.0   \n",
       "4  [great, taffy, great, price, wide, assortment,...    0.0   \n",
       "\n",
       "                                         rawfeatures  \\\n",
       "0  (0.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 4.0, 4.0, ...   \n",
       "1  (0.0, 2.0, 4.0, 1.0, 2.0, 0.0, 0.0, 4.0, 0.0, ...   \n",
       "2  (2.0, 3.0, 5.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, ...   \n",
       "3  (2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...   \n",
       "4  (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, ...   \n",
       "\n",
       "                                            features  \n",
       "0  (0.0, 1.3131902060863196, 0.7708544287433142, ...  \n",
       "1  (0.0, 0.8754601373908798, 1.5417088574866284, ...  \n",
       "2  (0.5112818338139713, 1.3131902060863196, 1.927...  \n",
       "3  (0.5112818338139713, 0.4377300686954399, 0.0, ...  \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.3824030925114636, 0.0, ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDFfeaturizedData.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "word2Vec = Word2Vec(vectorSize=3, minCount=0, inputCol=\"filtered\", outputCol=\"features\")\n",
    "model = word2Vec.fit(feature_data)\n",
    "\n",
    "W2VfeaturizedData = model.transform(feature_data)\n",
    "# W2VfeaturizedData.show(1,False)\n",
    "\n",
    "# W2Vec Dataframes typically has negative values so we will correct for that here so that we can use the Naive Bayes classifier\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "# Compute summary statistics and generate MinMaxScalerModel\n",
    "scalerModel = scaler.fit(W2VfeaturizedData)\n",
    "\n",
    "# rescale each feature to range [min, max].\n",
    "scaled_data = scalerModel.transform(W2VfeaturizedData)\n",
    "W2VfeaturizedData = scaled_data.select('Text','label','scaledFeatures')\n",
    "W2VfeaturizedData = W2VfeaturizedData.withColumnRenamed('scaledFeatures','features')\n",
    "\n",
    "W2VfeaturizedData.name = 'W2VfeaturizedData' # We will need this to print later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Evaluate your model\n",
    "\n",
    "From here on out, is straight up classification. So we can go and use our trusty function! I'll just go ahead and copy and paste it in here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our evaluation objects\n",
    "Bin_evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction') #labelCol='label'\n",
    "# Bin_evaluator = BinaryClassificationEvaluator() #labelCol='label'\n",
    "MC_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\") # redictionCol=\"prediction\","
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate using HTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTF=HTFfeaturizedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i have bought several of the vitality canned d...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[i, have, bought, several, of, the, vitality, ...</td>\n",
       "      <td>[bought, several, vitality, canned, dog, food,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 4.0, 4.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[product, arrived, labeled, as, jumbo, salted,...</td>\n",
       "      <td>[product, arrived, labeled, jumbo, salted, pea...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 2.0, 4.0, 1.0, 2.0, 0.0, 0.0, 4.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is a confection that has been around a fe...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[this, is, a, confection, that, has, been, aro...</td>\n",
       "      <td>[confection, around, centuries, light, pillowy...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(2.0, 3.0, 5.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you are looking for the secret ingredient i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[if, you, are, looking, for, the, secret, ingr...</td>\n",
       "      <td>[looking, secret, ingredient, robitussin, beli...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy at a great price there was a wide ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[great, taffy, at, a, great, price, there, was...</td>\n",
       "      <td>[great, taffy, great, price, wide, assortment,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text     Score  \\\n",
       "0  i have bought several of the vitality canned d...  positive   \n",
       "1  product arrived labeled as jumbo salted peanut...  negative   \n",
       "2  this is a confection that has been around a fe...  positive   \n",
       "3  if you are looking for the secret ingredient i...  negative   \n",
       "4  great taffy at a great price there was a wide ...  positive   \n",
       "\n",
       "                                               words  \\\n",
       "0  [i, have, bought, several, of, the, vitality, ...   \n",
       "1  [product, arrived, labeled, as, jumbo, salted,...   \n",
       "2  [this, is, a, confection, that, has, been, aro...   \n",
       "3  [if, you, are, looking, for, the, secret, ingr...   \n",
       "4  [great, taffy, at, a, great, price, there, was...   \n",
       "\n",
       "                                            filtered  label  \\\n",
       "0  [bought, several, vitality, canned, dog, food,...    0.0   \n",
       "1  [product, arrived, labeled, jumbo, salted, pea...    1.0   \n",
       "2  [confection, around, centuries, light, pillowy...    0.0   \n",
       "3  [looking, secret, ingredient, robitussin, beli...    1.0   \n",
       "4  [great, taffy, great, price, wide, assortment,...    0.0   \n",
       "\n",
       "                                            features  \n",
       "0  (0.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 4.0, 4.0, ...  \n",
       "1  (0.0, 2.0, 4.0, 1.0, 2.0, 0.0, 0.0, 4.0, 0.0, ...  \n",
       "2  (2.0, 3.0, 5.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, ...  \n",
       "3  (2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...  \n",
       "4  (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTF.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTF = HTF.select('features','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 4.0, 4.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.0, 2.0, 4.0, 1.0, 2.0, 0.0, 0.0, 4.0, 0.0, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(2.0, 3.0, 5.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features  label\n",
       "0  (0.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 4.0, 4.0, ...    0.0\n",
       "1  (0.0, 2.0, 4.0, 1.0, 2.0, 0.0, 0.0, 4.0, 0.0, ...    1.0\n",
       "2  (2.0, 3.0, 5.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, ...    0.0\n",
       "3  (2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...    1.0\n",
       "4  (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, ...    0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTF.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and test dataset 70:30 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = HTF.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5009030748771118\n",
      "Accuracy: 83.15 %\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# This is the most simplistic approach which does not use cross validation\n",
    "# Let's go ahead and train a Logistic Regression Algorithm\n",
    "classifier = LogisticRegression()\n",
    "fitModel = classifier.fit(train)\n",
    "\n",
    "# Evaluation method for binary classification problem\n",
    "predictionAndLabels = fitModel.transform(test)\n",
    "auc = Bin_evaluator.evaluate(predictionAndLabels)\n",
    "print(\"AUC:\",auc)\n",
    "\n",
    "# Evaluation for a multiclass classification problem\n",
    "predictions = fitModel.transform(test)\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(\"Accuracy: {0:.2f}\".format(accuracy),\"%\") \n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: [-1.7552356928419908]\n",
      "Coefficients: \n",
      "DenseMatrix([[-0.0458688 , -0.04132501,  0.0649768 , -0.00604277,  0.05469958,\n",
      "               0.00067068,  0.01100899,  0.0090707 , -0.03797806, -0.01824852,\n",
      "               0.00506662,  0.00809073,  0.03650167, -0.05553102,  0.00569813,\n",
      "               0.01660173,  0.01792814, -0.014733  ,  0.0740175 , -0.01065871]])\n",
      "83.1454714228882\n"
     ]
    }
   ],
   "source": [
    "# First tell Spark which classifier you want to use\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# Then Set up your parameter grid for the cross validator to conduct hyperparameter tuning\n",
    "paramGrid = (ParamGridBuilder().addGrid(classifier.maxIter, [10, 15,20]).build())\n",
    "\n",
    "# Then set up the Cross Validator which requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MC_evaluator,\n",
    "                          numFolds=2) # 3 + is best practice\n",
    "\n",
    "# Then fit your model\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "# Collect the best model and\n",
    "# print the coefficient matrix\n",
    "# These values should be compared relative to eachother\n",
    "# And intercepts can be prepared to other models\n",
    "BestModel = fitModel.bestModel\n",
    "print(\"Intercept: \" + str(BestModel.interceptVector))\n",
    "print(\"Coefficients: \\n\" + str(BestModel.coefficientMatrix))\n",
    "\n",
    "# You can extract the best model from this run like this if you want\n",
    "LR_BestModel = BestModel\n",
    "\n",
    "# Next you need to generate predictions on the test dataset\n",
    "# fitModel automatically uses the best model \n",
    "# so we don't need to use BestModel here\n",
    "predictions = fitModel.transform(test)\n",
    "\n",
    "# Now print the accuracy rate of the model or AUC for a binary classifier\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/varun/anaconda3/lib/python3.8/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------+\n",
      "|summary|             label|          prediction|\n",
      "+-------+------------------+--------------------+\n",
      "|  count|             34917|               34917|\n",
      "|   mean|0.1627287567660452|9.737377208809462E-4|\n",
      "| stddev|0.3691233000715696| 0.03119002110587992|\n",
      "|    min|               0.0|                 0.0|\n",
      "|    max|               1.0|                 1.0|\n",
      "+-------+------------------+--------------------+\n",
      "\n",
      " \n",
      "objectiveHistory: (scaled loss + regularization) at each iteration\n",
      "0.4441672055289093\n",
      "0.44262624396381306\n",
      "0.44162110090017065\n",
      "0.43846986595127413\n",
      "0.43843875718076086\n",
      "0.4384280294909694\n",
      "0.43842610172043195\n",
      "0.4384255876771879\n",
      "0.4384255285867055\n",
      "0.4384255251048576\n",
      "0.4384255248081934\n",
      " \n",
      "False positive rate by label:\n",
      "label 0: 0.9985920450545582\n",
      "label 1: 0.0008893449632290064\n",
      " \n",
      "True positive rate by label:\n",
      "label 0: 0.999110655036771\n",
      "label 1: 0.0014079549454417458\n",
      " \n",
      "Precision by label:\n",
      "label 0: 0.8373419717340825\n",
      "label 1: 0.23529411764705882\n",
      " \n",
      "Recall by label:\n",
      "label 0: 0.999110655036771\n",
      "label 1: 0.0014079549454417458\n",
      " \n",
      "F-measure by label:\n",
      "label 0: 0.9111014067812472\n",
      "label 1: 0.0027991602519244225\n",
      " \n",
      "Accuracy: 0.8367557350287825\n",
      "FPR: 0.8362371250465698\n",
      "TPR: 0.8367557350287825\n",
      "F-measure: 0.7632945114357246\n",
      "Precision: 0.7393714729248357\n",
      "Recall: 0.8367557350287825\n"
     ]
    }
   ],
   "source": [
    "# Load the Summary\n",
    "trainingSummary = LR_BestModel.summary\n",
    "\n",
    "# General Describe\n",
    "trainingSummary.predictions.describe().show()\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\" \")\n",
    "print(\"objectiveHistory: (scaled loss + regularization) at each iteration\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# for multiclass, we can inspect metrics on a per-label basis\n",
    "print(\" \")\n",
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\" \")\n",
    "print(\"True positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\" \")\n",
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "print(\" \")\n",
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "print(\" \")\n",
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "# Generate confusion matrix and print (includes accuracy)\n",
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\" \")\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One vs. Rest\n",
    "Recap from lecture The One-vs-Rest classifier is a type of multiclass classifier that involves training a single classifier per class, with the samples of that class as positive samples and all other samples as negatives. So each class is viewed as it compares to rest of the classes as a whole, as opposed to each one individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mIntercept: \u001b[0m 1.7562212198980984 \u001b[1m\n",
      "Coefficients:\u001b[0m [0.03916173632684779,0.035156926314581984,-0.056674186496254074,0.00473309147734678,-0.047524822771146336,-0.0011739823293586322,-0.009425113974763134,-0.00866796444555344,0.031154257959753993,0.015776249717221972,-0.004658416328512517,-0.007286548577725694,-0.03197465970689617,0.046330321108072156,-0.005208539204358248,-0.01362685984205546,-0.015065824769997061,0.011532426330988733,-0.0647510773099216,0.008821781387471066]\n",
      "\u001b[1mIntercept: \u001b[0m -1.7562212198980982 \u001b[1m\n",
      "Coefficients:\u001b[0m [-0.03916173632684776,-0.03515692631458197,0.056674186496254074,-0.004733091477346791,0.0475248227711463,0.0011739823293586455,0.009425113974763163,0.008667964445553459,-0.031154257959754038,-0.015776249717221975,0.004658416328512565,0.007286548577725655,0.03197465970689616,-0.04633032110807215,0.005208539204358288,0.013626859842055436,0.015065824769997058,-0.011532426330988728,0.0647510773099216,-0.008821781387471112]\n",
      "83.13221058215092\n"
     ]
    }
   ],
   "source": [
    "# instantiate the base classifier.\n",
    "lr = LogisticRegression()\n",
    "# instantiate the One Vs Rest Classifier.\n",
    "classifier = OneVsRest(classifier=lr)\n",
    "\n",
    "# Add parameters of your choice here:\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .build()\n",
    "#Cross Validator requires the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 is best practice\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "# Print the Coefficients\n",
    "# First we need to extract the best model from fit model\n",
    "\n",
    "# Get Best Model\n",
    "BestModel = fitModel.bestModel\n",
    "# Extract list of binary models\n",
    "models = BestModel.models\n",
    "for model in models:\n",
    "    print('\\033[1m' + 'Intercept: '+ '\\033[0m',model.intercept,'\\033[1m' + '\\nCoefficients:'+ '\\033[0m',model.coefficients)\n",
    "        \n",
    "# Now generate predictions on test dataset\n",
    "predictions = fitModel.transform(test)\n",
    "# And calculate the accuracy score\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "# And print\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mModel Weights: \u001b[0m 923\n",
      "Accuracy:  83.17862352473146\n"
     ]
    }
   ],
   "source": [
    "# Count how many features you have\n",
    "features = HTF.select(['features']).collect()\n",
    "features_count = len(features[0][0])\n",
    "# Count how many classes you have \n",
    "class_count = HTF.select(countDistinct(\"label\")).collect()\n",
    "classes = class_count[0][0]\n",
    "\n",
    "# Then use this number to specify the layers\n",
    "# The first number in this list is the input layer which has to be equal to the number of features in your vector\n",
    "# The second number is the first hidden layer\n",
    "# The third number is the second hidden layer \n",
    "# The fourth number is the output layer which has to be equal to your class size\n",
    "layers = [features_count, features_count+1, features_count, classes]\n",
    "# Instaniate the classifier\n",
    "classifier = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "\n",
    "# Fit the model\n",
    "fitModel = classifier.fit(train)\n",
    "\n",
    "# Print the model Weights\n",
    "print('\\033[1m' + \"Model Weights: \"+ '\\033[0m',fitModel.weights.size)\n",
    "   \n",
    "# Generate predictions on test dataframe\n",
    "predictions = fitModel.transform(test)\n",
    "# Calculate accuracy score\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "# Print accuracy score\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  83.09242805993901\n"
     ]
    }
   ],
   "source": [
    "# Add parameters of your choice here:\n",
    "classifier = NaiveBayes()\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "             .addGrid(classifier.smoothing, [0.0, 0.2, 0.4, 0.6]) \\\n",
    "             .build())\n",
    "\n",
    "#Cross Validator requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 + is best practice\n",
    "# Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "predictions = fitModel.transform(test)\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: \n",
      "-1.0006773247335061\n",
      "\u001b[1m Coefficients\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "[-0.00035307353654296834,-0.0005490781608652362,0.0,-0.0004860194616013917,0.0,0.0,0.0,-7.44495262994637e-05,-0.0006117979350420631,0.0,0.0,-0.00029164920941916723,0.0,-0.0009463157955664083,0.0,0.0012536082826390459,0.0010541717755659904,-0.0005881226613804043,0.0,0.00042638426570139066]\n",
      "Accuracy:  83.23166688768067\n"
     ]
    }
   ],
   "source": [
    "# Count how many classes you have and produce an error if it's more than 2.\n",
    "class_count = HTF.select(countDistinct(\"label\")).collect()\n",
    "classes = class_count[0][0]\n",
    "if classes > 2:\n",
    "    print(\"LinearSVC cannot be used because PySpark currently only accepts binary classification data for this algorithm\")\n",
    "\n",
    "# Add parameters of your choice here:\n",
    "classifier = LinearSVC()\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "             .addGrid(classifier.maxIter, [10, 15]) \\\n",
    "             .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
    "             .build())\n",
    "\n",
    "#Cross Validator requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 + is best practice\n",
    "# Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "BestModel = fitModel.bestModel\n",
    "\n",
    "print(\"Intercept: \\n\" + str(BestModel.intercept))\n",
    "print('\\033[1m' + \" Coefficients\"+ '\\033[0m')\n",
    "print(\"You should compares these relative to eachother\")\n",
    "print(\"Coefficients: \\n\" + str(BestModel.coefficients))\n",
    "    \n",
    "# Automatically gets the best model\n",
    "predictions = fitModel.transform(test)\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:  [0.0170495  0.         0.         0.         0.15897238 0.05901237\n",
      " 0.         0.02260163 0.         0.01463241 0.         0.\n",
      " 0.09054291 0.06136892 0.         0.08208282 0.05856106 0.02156435\n",
      " 0.36902538 0.04458628]\n",
      "Accuracy:  83.19851478583742\n"
     ]
    }
   ],
   "source": [
    "# Add parameters of your choice here:\n",
    "classifier = DecisionTreeClassifier()\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "             .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "             .build())\n",
    "\n",
    "#Cross Validator requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 + is best practice\n",
    "# Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "# Collect and print feature importances\n",
    "BestModel = fitModel.bestModel\n",
    "featureImportances = BestModel.featureImportances.toArray()\n",
    "print(\"Feature Importances: \",featureImportances)\n",
    "\n",
    "predictions = fitModel.transform(test)\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:  [0.06020908 0.03939737 0.07056043 0.03823435 0.05812769 0.03984151\n",
      " 0.04801501 0.05225476 0.04689558 0.04124826 0.05142836 0.04313354\n",
      " 0.05872751 0.05157523 0.04310136 0.05637617 0.04787212 0.04896633\n",
      " 0.06660303 0.03743231]\n",
      " \n",
      "Accuracy:  83.29134067099854\n"
     ]
    }
   ],
   "source": [
    "# Add parameters of your choice here:\n",
    "classifier = RandomForestClassifier()\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "               .addGrid(classifier.maxDepth, [2, 5, 10])\n",
    "#                                .addGrid(classifier.maxBins, [5, 10, 20])\n",
    "#                                .addGrid(classifier.numTrees, [5, 20, 50])\n",
    "             .build())\n",
    "\n",
    "#Cross Validator requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 + is best practice\n",
    "\n",
    "# Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "# Retrieve best model from cross val\n",
    "BestModel = fitModel.bestModel\n",
    "featureImportances = BestModel.featureImportances.toArray()\n",
    "print(\"Feature Importances: \",featureImportances)\n",
    "\n",
    "predictions = fitModel.transform(test)\n",
    "\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(\" \")\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:  [0.06000566 0.04120609 0.05678355 0.04895157 0.0597304  0.03591276\n",
      " 0.05130978 0.0512845  0.05811942 0.05014301 0.05865339 0.0435035\n",
      " 0.05003062 0.04635694 0.04065306 0.05319584 0.04429699 0.04715108\n",
      " 0.05827277 0.04443907]\n",
      " \n",
      "Accuracy:  83.11231932104496\n"
     ]
    }
   ],
   "source": [
    "class_count = HTF.select(countDistinct(\"label\")).collect()\n",
    "classes = class_count[0][0]\n",
    "if classes > 2:\n",
    "    print(\"GBTClassifier cannot be used because PySpark currently only accepts binary classification data for this algorithm\")\n",
    "\n",
    "# Add parameters of your choice here:\n",
    "classifier = GBTClassifier()\n",
    "\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "#                              .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "             .addGrid(classifier.maxIter, [10, 15,50,100])\n",
    "             .build())\n",
    "\n",
    "#Cross Validator requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 + is best practice\n",
    "\n",
    "# Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "BestModel = fitModel.bestModel\n",
    "featureImportances = BestModel.featureImportances.toArray()\n",
    "print(\"Feature Importances: \",featureImportances)\n",
    "    \n",
    "predictions = fitModel.transform(test)\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(\" \")\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate using Tf_Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf=TFIDFfeaturizedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>label</th>\n",
       "      <th>rawfeatures</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i have bought several of the vitality canned d...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[i, have, bought, several, of, the, vitality, ...</td>\n",
       "      <td>[bought, several, vitality, canned, dog, food,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 4.0, 4.0, ...</td>\n",
       "      <td>(0.0, 1.3131902060863196, 0.7708544287433142, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[product, arrived, labeled, as, jumbo, salted,...</td>\n",
       "      <td>[product, arrived, labeled, jumbo, salted, pea...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 2.0, 4.0, 1.0, 2.0, 0.0, 0.0, 4.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.8754601373908798, 1.5417088574866284, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is a confection that has been around a fe...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[this, is, a, confection, that, has, been, aro...</td>\n",
       "      <td>[confection, around, centuries, light, pillowy...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(2.0, 3.0, 5.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, ...</td>\n",
       "      <td>(0.5112818338139713, 1.3131902060863196, 1.927...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you are looking for the secret ingredient i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[if, you, are, looking, for, the, secret, ingr...</td>\n",
       "      <td>[looking, secret, ingredient, robitussin, beli...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>(0.5112818338139713, 0.4377300686954399, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy at a great price there was a wide ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[great, taffy, at, a, great, price, there, was...</td>\n",
       "      <td>[great, taffy, great, price, wide, assortment,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.3824030925114636, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text     Score  \\\n",
       "0  i have bought several of the vitality canned d...  positive   \n",
       "1  product arrived labeled as jumbo salted peanut...  negative   \n",
       "2  this is a confection that has been around a fe...  positive   \n",
       "3  if you are looking for the secret ingredient i...  negative   \n",
       "4  great taffy at a great price there was a wide ...  positive   \n",
       "\n",
       "                                               words  \\\n",
       "0  [i, have, bought, several, of, the, vitality, ...   \n",
       "1  [product, arrived, labeled, as, jumbo, salted,...   \n",
       "2  [this, is, a, confection, that, has, been, aro...   \n",
       "3  [if, you, are, looking, for, the, secret, ingr...   \n",
       "4  [great, taffy, at, a, great, price, there, was...   \n",
       "\n",
       "                                            filtered  label  \\\n",
       "0  [bought, several, vitality, canned, dog, food,...    0.0   \n",
       "1  [product, arrived, labeled, jumbo, salted, pea...    1.0   \n",
       "2  [confection, around, centuries, light, pillowy...    0.0   \n",
       "3  [looking, secret, ingredient, robitussin, beli...    1.0   \n",
       "4  [great, taffy, great, price, wide, assortment,...    0.0   \n",
       "\n",
       "                                         rawfeatures  \\\n",
       "0  (0.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 4.0, 4.0, ...   \n",
       "1  (0.0, 2.0, 4.0, 1.0, 2.0, 0.0, 0.0, 4.0, 0.0, ...   \n",
       "2  (2.0, 3.0, 5.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, ...   \n",
       "3  (2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...   \n",
       "4  (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, ...   \n",
       "\n",
       "                                            features  \n",
       "0  (0.0, 1.3131902060863196, 0.7708544287433142, ...  \n",
       "1  (0.0, 0.8754601373908798, 1.5417088574866284, ...  \n",
       "2  (0.5112818338139713, 1.3131902060863196, 1.927...  \n",
       "3  (0.5112818338139713, 0.4377300686954399, 0.0, ...  \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.3824030925114636, 0.0, ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = tf_idf.select('features','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 1.3131902060863196, 0.7708544287433142, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.0, 0.8754601373908798, 1.5417088574866284, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.5112818338139713, 1.3131902060863196, 1.927...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.5112818338139713, 0.4377300686954399, 0.0, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.3824030925114636, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features  label\n",
       "0  (0.0, 1.3131902060863196, 0.7708544287433142, ...    0.0\n",
       "1  (0.0, 0.8754601373908798, 1.5417088574866284, ...    1.0\n",
       "2  (0.5112818338139713, 1.3131902060863196, 1.927...    0.0\n",
       "3  (0.5112818338139713, 0.4377300686954399, 0.0, ...    1.0\n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.3824030925114636, 0.0, ...    0.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and test dataset 70:30 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = tf_idf.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5007538720417449\n",
      "Accuracy: 83.28 %\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# This is the most simplistic approach which does not use cross validation\n",
    "# Let's go ahead and train a Logistic Regression Algorithm\n",
    "classifier = LogisticRegression()\n",
    "fitModel = classifier.fit(train)\n",
    "\n",
    "# Evaluation method for binary classification problem\n",
    "predictionAndLabels = fitModel.transform(test)\n",
    "auc = Bin_evaluator.evaluate(predictionAndLabels)\n",
    "print(\"AUC:\",auc)\n",
    "\n",
    "# Evaluation for a multiclass classification problem\n",
    "predictions = fitModel.transform(test)\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(\"Accuracy: {0:.2f}\".format(accuracy),\"%\") #     print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: [-1.739762372354217]\n",
      "Coefficients: \n",
      "DenseMatrix([[-0.16772199, -0.10669487,  0.1930526 , -0.06237147,  0.14219767,\n",
      "              -0.00458707,  0.01636683,  0.03149717, -0.1486108 , -0.08092725,\n",
      "              -0.00643504,  0.03529166,  0.15469715, -0.17743527, -0.00495268,\n",
      "               0.06287747,  0.04761007, -0.00875633,  0.17464348, -0.01523864]])\n",
      "83.27810180275715\n"
     ]
    }
   ],
   "source": [
    "# First tell Spark which classifier you want to use\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# Then Set up your parameter grid for the cross validator to conduct hyperparameter tuning\n",
    "paramGrid = (ParamGridBuilder().addGrid(classifier.maxIter, [10, 15,20]).build())\n",
    "\n",
    "# Then set up the Cross Validator which requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MC_evaluator,\n",
    "                          numFolds=2) # 3 + is best practice\n",
    "\n",
    "# Then fit your model\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "# Collect the best model and\n",
    "# print the coefficient matrix\n",
    "# These values should be compared relative to eachother\n",
    "# And intercepts can be prepared to other models\n",
    "BestModel = fitModel.bestModel\n",
    "print(\"Intercept: \" + str(BestModel.interceptVector))\n",
    "print(\"Coefficients: \\n\" + str(BestModel.coefficientMatrix))\n",
    "\n",
    "# You can extract the best model from this run like this if you want\n",
    "LR_BestModel = BestModel\n",
    "\n",
    "# Next you need to generate predictions on the test dataset\n",
    "# fitModel automatically uses the best model \n",
    "# so we don't need to use BestModel here\n",
    "predictions = fitModel.transform(test)\n",
    "\n",
    "# Now print the accuracy rate of the model or AUC for a binary classifier\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/varun/anaconda3/lib/python3.8/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+--------------------+\n",
      "|summary|              label|          prediction|\n",
      "+-------+-------------------+--------------------+\n",
      "|  count|              34911|               34911|\n",
      "|   mean|0.16307181117699293|0.001690011744149...|\n",
      "| stddev|0.36943646955959625|0.041075588044162406|\n",
      "|    min|                0.0|                 0.0|\n",
      "|    max|                1.0|                 1.0|\n",
      "+-------+-------------------+--------------------+\n",
      "\n",
      " \n",
      "objectiveHistory: (scaled loss + regularization) at each iteration\n",
      "0.4447287187443416\n",
      "0.4431910806032841\n",
      "0.4419524355367641\n",
      "0.4383240446218865\n",
      "0.43827161266027753\n",
      "0.4382593171290481\n",
      "0.43825598410140554\n",
      "0.43825536794588954\n",
      "0.43825529161228394\n",
      "0.438255287165618\n",
      "0.43825528653432017\n",
      " \n",
      "False positive rate by label:\n",
      "label 0: 0.9973651853152995\n",
      "label 1: 0.001505921007598056\n",
      " \n",
      "True positive rate by label:\n",
      "label 0: 0.998494078992402\n",
      "label 1: 0.0026348146847005095\n",
      " \n",
      "Precision by label:\n",
      "label 0: 0.8370825203718582\n",
      "label 1: 0.2542372881355932\n",
      " \n",
      "Recall by label:\n",
      "label 0: 0.998494078992402\n",
      "label 1: 0.0026348146847005095\n",
      " \n",
      "F-measure by label:\n",
      "label 0: 0.9106914312470735\n",
      "label 1: 0.00521557719054242\n",
      " \n",
      "Accuracy: 0.8360975050843573\n",
      "FPR: 0.8349686114072549\n",
      "TPR: 0.8360975050843573\n",
      "F-measure: 0.7630338437490405\n",
      "Precision: 0.7420368927152154\n",
      "Recall: 0.8360975050843573\n"
     ]
    }
   ],
   "source": [
    "# Load the Summary\n",
    "trainingSummary = LR_BestModel.summary\n",
    "\n",
    "# General Describe\n",
    "trainingSummary.predictions.describe().show()\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\" \")\n",
    "print(\"objectiveHistory: (scaled loss + regularization) at each iteration\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# for multiclass, we can inspect metrics on a per-label basis\n",
    "print(\" \")\n",
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\" \")\n",
    "print(\"True positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\" \")\n",
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "print(\" \")\n",
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "print(\" \")\n",
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "# Generate confusion matrix and print (includes accuracy)\n",
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\" \")\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One vs. Rest\n",
    "Recap from lecture The One-vs-Rest classifier is a type of multiclass classifier that involves training a single classifier per class, with the samples of that class as positive samples and all other samples as negatives. So each class is viewed as it compares to rest of the classes as a whole, as opposed to each one individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mIntercept: \u001b[0m 1.7420281793148344 \u001b[1m\n",
      "Coefficients:\u001b[0m [0.14307963346299235,0.09056419819629825,-0.16784392032699819,0.051061306357161655,-0.12367325819801774,0.002344284711907399,-0.014036012294216584,-0.029979669492204878,0.1221436720127177,0.06970948849092526,0.0049318753372649465,-0.03167745542820083,-0.1346814328739016,0.14861053163477678,0.004086692731493456,-0.05214892625370983,-0.04006441884310158,0.0043179028011782064,-0.1525613332074583,0.012085668069256343]\n",
      "\u001b[1mIntercept: \u001b[0m -1.742028179314835 \u001b[1m\n",
      "Coefficients:\u001b[0m [-0.14307963346299227,-0.09056419819629828,0.16784392032699824,-0.051061306357161516,0.12367325819801768,-0.0023442847119073363,0.014036012294216525,0.02997966949220505,-0.12214367201271781,-0.06970948849092524,-0.004931875337264979,0.03167745542820068,0.13468143287390147,-0.14861053163477678,-0.004086692731493408,0.05214892625370964,0.040064418843101635,-0.004317902801178229,0.15256133320745846,-0.012085668069256292]\n",
      "83.29798515376459\n"
     ]
    }
   ],
   "source": [
    "# instantiate the base classifier.\n",
    "lr = LogisticRegression()\n",
    "# instantiate the One Vs Rest Classifier.\n",
    "classifier = OneVsRest(classifier=lr)\n",
    "\n",
    "# Add parameters of your choice here:\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .build()\n",
    "#Cross Validator requires the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 is best practice\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "# Print the Coefficients\n",
    "# First we need to extract the best model from fit model\n",
    "\n",
    "# Get Best Model\n",
    "BestModel = fitModel.bestModel\n",
    "# Extract list of binary models\n",
    "models = BestModel.models\n",
    "for model in models:\n",
    "    print('\\033[1m' + 'Intercept: '+ '\\033[0m',model.intercept,'\\033[1m' + '\\nCoefficients:'+ '\\033[0m',model.coefficients)\n",
    "        \n",
    "# Now generate predictions on test dataset\n",
    "predictions = fitModel.transform(test)\n",
    "# And calculate the accuracy score\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "# And print\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mModel Weights: \u001b[0m 923\n",
      "Accuracy:  83.31786850477201\n"
     ]
    }
   ],
   "source": [
    "# Count how many features you have\n",
    "features = tf_idf.select(['features']).collect()\n",
    "features_count = len(features[0][0])\n",
    "# Count how many classes you have \n",
    "class_count = tf_idf.select(countDistinct(\"label\")).collect()\n",
    "classes = class_count[0][0]\n",
    "\n",
    "# Then use this number to specify the layers\n",
    "# The first number in this list is the input layer which has to be equal to the number of features in your vector\n",
    "# The second number is the first hidden layer\n",
    "# The third number is the second hidden layer \n",
    "# The fourth number is the output layer which has to be equal to your class size\n",
    "layers = [features_count, features_count+1, features_count, classes]\n",
    "# Instaniate the classifier\n",
    "classifier = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "\n",
    "# Fit the model\n",
    "fitModel = classifier.fit(train)\n",
    "\n",
    "# Print the model Weights\n",
    "print('\\033[1m' + \"Model Weights: \"+ '\\033[0m',fitModel.weights.size)\n",
    "   \n",
    "# Generate predictions on test dataframe\n",
    "predictions = fitModel.transform(test)\n",
    "# Calculate accuracy score\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "# Print accuracy score\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  83.31124072110286\n"
     ]
    }
   ],
   "source": [
    "# Add parameters of your choice here:\n",
    "classifier = NaiveBayes()\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "             .addGrid(classifier.smoothing, [0.0, 0.2, 0.4, 0.6]) \\\n",
    "             .build())\n",
    "\n",
    "#Cross Validator requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 + is best practice\n",
    "# Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "predictions = fitModel.transform(test)\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: \n",
      "-1.0082883209353788\n",
      "\u001b[1m Coefficients\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "[-0.006055138393847619,-0.004954237622905466,0.0025206419775702,-0.0072919574205939095,0.008076459221482814,0.003956149510343715,-0.0015851127298549443,0.00044834218347127844,-0.007149444931317731,-0.004188330611820416,-0.008288242604555485,0.002087474228905888,0.01104548053544675,-0.0053009979426403295,0.0,0.0029510539096506984,0.0018548571343827863,0.0045785196226850655,0.0012388463286382,-0.0004215029370989358]\n",
      "Accuracy:  83.31124072110286\n"
     ]
    }
   ],
   "source": [
    "# Count how many classes you have and produce an error if it's more than 2.\n",
    "class_count = tf_idf.select(countDistinct(\"label\")).collect()\n",
    "classes = class_count[0][0]\n",
    "if classes > 2:\n",
    "    print(\"LinearSVC cannot be used because PySpark currently only accepts binary classification data for this algorithm\")\n",
    "\n",
    "# Add parameters of your choice here:\n",
    "classifier = LinearSVC()\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "             .addGrid(classifier.maxIter, [10, 15]) \\\n",
    "             .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
    "             .build())\n",
    "\n",
    "#Cross Validator requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 + is best practice\n",
    "# Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "BestModel = fitModel.bestModel\n",
    "\n",
    "print(\"Intercept: \\n\" + str(BestModel.intercept))\n",
    "print('\\033[1m' + \" Coefficients\"+ '\\033[0m')\n",
    "print(\"You should compares these relative to eachother\")\n",
    "print(\"Coefficients: \\n\" + str(BestModel.coefficients))\n",
    "    \n",
    "# Automatically gets the best model\n",
    "predictions = fitModel.transform(test)\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:  [0.04348115 0.03112926 0.25340888 0.         0.07732208 0.\n",
      " 0.01869512 0.0163862  0.         0.         0.         0.\n",
      " 0.         0.         0.02070184 0.06168935 0.0190686  0.03472348\n",
      " 0.39136731 0.03202673]\n",
      "Accuracy:  83.27810180275715\n"
     ]
    }
   ],
   "source": [
    "# Add parameters of your choice here:\n",
    "classifier = DecisionTreeClassifier()\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "             .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "             .build())\n",
    "\n",
    "#Cross Validator requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 + is best practice\n",
    "# Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "# Collect and print feature importances\n",
    "BestModel = fitModel.bestModel\n",
    "featureImportances = BestModel.featureImportances.toArray()\n",
    "print(\"Feature Importances: \",featureImportances)\n",
    "\n",
    "predictions = fitModel.transform(test)\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:  [0.06146049 0.04240204 0.0789521  0.04234037 0.06046521 0.04140761\n",
      " 0.04439617 0.04691719 0.04854666 0.04321129 0.05400712 0.03631441\n",
      " 0.05631209 0.04150863 0.04894504 0.05543624 0.0419969  0.04546184\n",
      " 0.06924306 0.04067555]\n",
      " \n",
      "Accuracy:  83.39077412513257\n"
     ]
    }
   ],
   "source": [
    "# Add parameters of your choice here:\n",
    "classifier = RandomForestClassifier()\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "               .addGrid(classifier.maxDepth, [2, 5, 10])\n",
    "#                                .addGrid(classifier.maxBins, [5, 10, 20])\n",
    "#                                .addGrid(classifier.numTrees, [5, 20, 50])\n",
    "             .build())\n",
    "\n",
    "#Cross Validator requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 + is best practice\n",
    "\n",
    "# Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "# Retrieve best model from cross val\n",
    "BestModel = fitModel.bestModel\n",
    "featureImportances = BestModel.featureImportances.toArray()\n",
    "print(\"Feature Importances: \",featureImportances)\n",
    "\n",
    "predictions = fitModel.transform(test)\n",
    "\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(\" \")\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:  [0.05264466 0.0489709  0.06427695 0.04452043 0.05883297 0.03739779\n",
      " 0.04118678 0.05431903 0.05324753 0.05530648 0.04880276 0.04650764\n",
      " 0.05761578 0.05138938 0.04543186 0.05298764 0.04232292 0.04905561\n",
      " 0.05731328 0.0378696 ]\n",
      " \n",
      "Accuracy:  83.15217391304348\n"
     ]
    }
   ],
   "source": [
    "class_count = tf_idf.select(countDistinct(\"label\")).collect()\n",
    "classes = class_count[0][0]\n",
    "if classes > 2:\n",
    "    print(\"GBTClassifier cannot be used because PySpark currently only accepts binary classification data for this algorithm\")\n",
    "\n",
    "# Add parameters of your choice here:\n",
    "classifier = GBTClassifier()\n",
    "\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "#                              .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "             .addGrid(classifier.maxIter, [10, 15,50,100])\n",
    "             .build())\n",
    "\n",
    "#Cross Validator requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 + is best practice\n",
    "\n",
    "# Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "BestModel = fitModel.bestModel\n",
    "featureImportances = BestModel.featureImportances.toArray()\n",
    "print(\"Feature Importances: \",featureImportances)\n",
    "    \n",
    "predictions = fitModel.transform(test)\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(\" \")\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate using W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2V=W2VfeaturizedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i have bought several of the vitality canned d...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.37703929231552025, 0.4992033522898879, 0.37...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.3369212129641121, 0.465928146427232, 0.4858...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is a confection that has been around a fe...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.5058178372353674, 0.4429592355448553, 0.527...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you are looking for the secret ingredient i...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.5585962595857322, 0.4035500947362397, 0.634...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy at a great price there was a wide ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.33080630765268737, 0.31161728536385536, 0.6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  label  \\\n",
       "0  i have bought several of the vitality canned d...    0.0   \n",
       "1  product arrived labeled as jumbo salted peanut...    1.0   \n",
       "2  this is a confection that has been around a fe...    0.0   \n",
       "3  if you are looking for the secret ingredient i...    1.0   \n",
       "4  great taffy at a great price there was a wide ...    0.0   \n",
       "\n",
       "                                            features  \n",
       "0  [0.37703929231552025, 0.4992033522898879, 0.37...  \n",
       "1  [0.3369212129641121, 0.465928146427232, 0.4858...  \n",
       "2  [0.5058178372353674, 0.4429592355448553, 0.527...  \n",
       "3  [0.5585962595857322, 0.4035500947362397, 0.634...  \n",
       "4  [0.33080630765268737, 0.31161728536385536, 0.6...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2V.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2V = W2V.select('features','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.37703929231552025, 0.4992033522898879, 0.37...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.3369212129641121, 0.465928146427232, 0.4858...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.5058178372353674, 0.4429592355448553, 0.527...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.5585962595857322, 0.4035500947362397, 0.634...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.33080630765268737, 0.31161728536385536, 0.6...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features  label\n",
       "0  [0.37703929231552025, 0.4992033522898879, 0.37...    0.0\n",
       "1  [0.3369212129641121, 0.465928146427232, 0.4858...    1.0\n",
       "2  [0.5058178372353674, 0.4429592355448553, 0.527...    0.0\n",
       "3  [0.5585962595857322, 0.4035500947362397, 0.634...    1.0\n",
       "4  [0.33080630765268737, 0.31161728536385536, 0.6...    0.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2V.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and test dataset 70:30 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test =W2V.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5023500871509174\n",
      "Accuracy: 83.54 %\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# This is the most simplistic approach which does not use cross validation\n",
    "# Let's go ahead and train a Logistic Regression Algorithm\n",
    "classifier = LogisticRegression()\n",
    "fitModel = classifier.fit(train)\n",
    "\n",
    "# Evaluation method for binary classification problem\n",
    "predictionAndLabels = fitModel.transform(test)\n",
    "auc = Bin_evaluator.evaluate(predictionAndLabels)\n",
    "print(\"AUC:\",auc)\n",
    "\n",
    "# Evaluation for a multiclass classification problem\n",
    "predictions = fitModel.transform(test)\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(\"Accuracy: {0:.2f}\".format(accuracy),\"%\") #     print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: [-8.73403647883886]\n",
      "Coefficients: \n",
      "DenseMatrix([[-9.80919095, 12.67384101, 11.12925288]])\n",
      "\n",
      "83.53523860518037\n"
     ]
    }
   ],
   "source": [
    "# First tell Spark which classifier you want to use\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# Then Set up your parameter grid for the cross validator to conduct hyperparameter tuning\n",
    "paramGrid = (ParamGridBuilder().addGrid(classifier.maxIter, [10, 15,20]).build())\n",
    "\n",
    "# Then set up the Cross Validator which requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MC_evaluator,\n",
    "                          numFolds=2) # 3 + is best practice\n",
    "\n",
    "# Then fit your model\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "# Collect the best model and\n",
    "# print the coefficient matrix\n",
    "# These values should be compared relative to eachother\n",
    "# And intercepts can be prepared to other models\n",
    "BestModel = fitModel.bestModel\n",
    "print(\"Intercept: \" + str(BestModel.interceptVector))\n",
    "print(\"Coefficients: \\n\" + str(BestModel.coefficientMatrix))\n",
    "\n",
    "# You can extract the best model from this run like this if you want\n",
    "LR_BestModel = BestModel\n",
    "\n",
    "# Next you need to generate predictions on the test dataset\n",
    "# fitModel automatically uses the best model \n",
    "# so we don't need to use BestModel here\n",
    "predictions = fitModel.transform(test)\n",
    "\n",
    "# Now print the accuracy rate of the model or AUC for a binary classifier\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/varun/anaconda3/lib/python3.8/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+--------------------+\n",
      "|summary|              label|          prediction|\n",
      "+-------+-------------------+--------------------+\n",
      "|  count|              35058|               35058|\n",
      "|   mean|0.16435620970962406|0.002367505276969...|\n",
      "| stddev|0.37060378270058114| 0.04860007786901043|\n",
      "|    min|                0.0|                 0.0|\n",
      "|    max|                1.0|                 1.0|\n",
      "+-------+-------------------+--------------------+\n",
      "\n",
      " \n",
      "objectiveHistory: (scaled loss + regularization) at each iteration\n",
      "0.4468233827202532\n",
      "0.44278460872843634\n",
      "0.44155663687416286\n",
      "0.43196426149801054\n",
      "0.4279279641407289\n",
      "0.4276879583135659\n",
      "0.42760956444362935\n",
      "0.42760593702596034\n",
      "0.4276058924327114\n",
      "0.4276058902273279\n",
      "0.4276058902220024\n",
      " \n",
      "False positive rate by label:\n",
      "label 0: 0.9951405761888233\n",
      "label 1: 0.001877389404696887\n",
      " \n",
      "True positive rate by label:\n",
      "label 0: 0.9981226105953032\n",
      "label 1: 0.004859423811176675\n",
      " \n",
      "Precision by label:\n",
      "label 0: 0.8360543245175125\n",
      "label 1: 0.3373493975903614\n",
      " \n",
      "Recall by label:\n",
      "label 0: 0.9981226105953032\n",
      "label 1: 0.004859423811176675\n",
      " \n",
      "F-measure by label:\n",
      "label 0: 0.9099282724712546\n",
      "label 1: 0.009580838323353293\n",
      " \n",
      "Accuracy: 0.8348736379713617\n",
      "FPR: 0.831891603564882\n",
      "TPR: 0.8348736379713617\n",
      "F-measure: 0.7619505807729202\n",
      "Precision: 0.7540890729642509\n",
      "Recall: 0.8348736379713617\n"
     ]
    }
   ],
   "source": [
    "# Load the Summary\n",
    "trainingSummary = LR_BestModel.summary\n",
    "\n",
    "# General Describe\n",
    "trainingSummary.predictions.describe().show()\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\" \")\n",
    "print(\"objectiveHistory: (scaled loss + regularization) at each iteration\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# for multiclass, we can inspect metrics on a per-label basis\n",
    "print(\" \")\n",
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\" \")\n",
    "print(\"True positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\" \")\n",
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "print(\" \")\n",
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "print(\" \")\n",
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "# Generate confusion matrix and print (includes accuracy)\n",
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\" \")\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One vs. Rest\n",
    "Recap from lecture The One-vs-Rest classifier is a type of multiclass classifier that involves training a single classifier per class, with the samples of that class as positive samples and all other samples as negatives. So each class is viewed as it compares to rest of the classes as a whole, as opposed to each one individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mIntercept: \u001b[0m 1.5769374860074399 \u001b[1m\n",
      "Coefficients:\u001b[0m [1.3000949495079814,-0.9683979716326919,-0.1922672880889995]\n",
      "\u001b[1mIntercept: \u001b[0m -1.5769374860074388 \u001b[1m\n",
      "Coefficients:\u001b[0m [-1.3000949495079814,0.9683979716326914,0.19226728808899865]\n",
      "83.60886152198648\n"
     ]
    }
   ],
   "source": [
    "# instantiate the base classifier.\n",
    "lr = LogisticRegression()\n",
    "# instantiate the One Vs Rest Classifier.\n",
    "classifier = OneVsRest(classifier=lr)\n",
    "\n",
    "# Add parameters of your choice here:\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .build()\n",
    "#Cross Validator requires the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 is best practice\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "# Print the Coefficients\n",
    "# First we need to extract the best model from fit model\n",
    "\n",
    "# Get Best Model\n",
    "BestModel = fitModel.bestModel\n",
    "# Extract list of binary models\n",
    "models = BestModel.models\n",
    "for model in models:\n",
    "    print('\\033[1m' + 'Intercept: '+ '\\033[0m',model.intercept,'\\033[1m' + '\\nCoefficients:'+ '\\033[0m',model.coefficients)\n",
    "        \n",
    "# Now generate predictions on test dataset\n",
    "predictions = fitModel.transform(test)\n",
    "# And calculate the accuracy score\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "# And print\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mModel Weights: \u001b[0m 39\n",
      "Accuracy:  83.6155545144234\n"
     ]
    }
   ],
   "source": [
    "# Count how many features you have\n",
    "features = W2V.select(['features']).collect()\n",
    "features_count = len(features[0][0])\n",
    "# Count how many classes you have \n",
    "class_count = W2V.select(countDistinct(\"label\")).collect()\n",
    "classes = class_count[0][0]\n",
    "\n",
    "# Then use this number to specify the layers\n",
    "# The first number in this list is the input layer which has to be equal to the number of features in your vector\n",
    "# The second number is the first hidden layer\n",
    "# The third number is the second hidden layer \n",
    "# The fourth number is the output layer which has to be equal to your class size\n",
    "layers = [features_count, features_count+1, features_count, classes]\n",
    "# Instaniate the classifier\n",
    "classifier = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "\n",
    "# Fit the model\n",
    "fitModel = classifier.fit(train)\n",
    "\n",
    "# Print the model Weights\n",
    "print('\\033[1m' + \"Model Weights: \"+ '\\033[0m',fitModel.weights.size)\n",
    "   \n",
    "# Generate predictions on test dataframe\n",
    "predictions = fitModel.transform(test)\n",
    "# Calculate accuracy score\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "# Print accuracy score\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  83.60886152198648\n"
     ]
    }
   ],
   "source": [
    "# Add parameters of your choice here:\n",
    "classifier = NaiveBayes()\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "             .addGrid(classifier.smoothing, [0.0, 0.2, 0.4, 0.6]) \\\n",
    "             .build())\n",
    "\n",
    "#Cross Validator requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 + is best practice\n",
    "# Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "predictions = fitModel.transform(test)\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: \n",
      "-1.1124333603133294\n",
      "\u001b[1m Coefficients\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "[-0.13533571729137764,0.17796321481569402,0.17104163386899277]\n",
      "Accuracy:  83.60886152198648\n"
     ]
    }
   ],
   "source": [
    "# Count how many classes you have and produce an error if it's more than 2.\n",
    "class_count = W2V.select(countDistinct(\"label\")).collect()\n",
    "classes = class_count[0][0]\n",
    "if classes > 2:\n",
    "    print(\"LinearSVC cannot be used because PySpark currently only accepts binary classification data for this algorithm\")\n",
    "\n",
    "# Add parameters of your choice here:\n",
    "classifier = LinearSVC()\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "             .addGrid(classifier.maxIter, [10, 15]) \\\n",
    "             .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
    "             .build())\n",
    "\n",
    "#Cross Validator requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 + is best practice\n",
    "# Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "BestModel = fitModel.bestModel\n",
    "\n",
    "print(\"Intercept: \\n\" + str(BestModel.intercept))\n",
    "print('\\033[1m' + \" Coefficients\"+ '\\033[0m')\n",
    "print(\"You should compares these relative to eachother\")\n",
    "print(\"Coefficients: \\n\" + str(BestModel.coefficients))\n",
    "    \n",
    "# Automatically gets the best model\n",
    "predictions = fitModel.transform(test)\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:  [0.45558102 0.49611745 0.04830153]\n",
      "Accuracy:  83.60886152198648\n"
     ]
    }
   ],
   "source": [
    "# Add parameters of your choice here:\n",
    "classifier = DecisionTreeClassifier()\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "             .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "             .build())\n",
    "\n",
    "#Cross Validator requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 + is best practice\n",
    "# Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "# Collect and print feature importances\n",
    "BestModel = fitModel.bestModel\n",
    "featureImportances = BestModel.featureImportances.toArray()\n",
    "print(\"Feature Importances: \",featureImportances)\n",
    "\n",
    "predictions = fitModel.transform(test)\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:  [0.33805675 0.35609284 0.3058504 ]\n",
      " \n",
      "Accuracy:  83.63563349173415\n"
     ]
    }
   ],
   "source": [
    "# Add parameters of your choice here:\n",
    "classifier = RandomForestClassifier()\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "               .addGrid(classifier.maxDepth, [2, 5, 10])\n",
    "#                                .addGrid(classifier.maxBins, [5, 10, 20])\n",
    "#                                .addGrid(classifier.numTrees, [5, 20, 50])\n",
    "             .build())\n",
    "\n",
    "#Cross Validator requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 + is best practice\n",
    "\n",
    "# Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "# Retrieve best model from cross val\n",
    "BestModel = fitModel.bestModel\n",
    "featureImportances = BestModel.featureImportances.toArray()\n",
    "print(\"Feature Importances: \",featureImportances)\n",
    "\n",
    "predictions = fitModel.transform(test)\n",
    "\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(\" \")\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:  [0.35424962 0.30067166 0.34507872]\n",
      " \n",
      "Accuracy:  83.49508065055886\n"
     ]
    }
   ],
   "source": [
    "class_count = W2V.select(countDistinct(\"label\")).collect()\n",
    "classes = class_count[0][0]\n",
    "if classes > 2:\n",
    "    print(\"GBTClassifier cannot be used because PySpark currently only accepts binary classification data for this algorithm\")\n",
    "\n",
    "# Add parameters of your choice here:\n",
    "classifier = GBTClassifier()\n",
    "\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "#                              .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "             .addGrid(classifier.maxIter, [10, 15,50,100])\n",
    "             .build())\n",
    "\n",
    "#Cross Validator requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 + is best practice\n",
    "\n",
    "# Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "BestModel = fitModel.bestModel\n",
    "featureImportances = BestModel.featureImportances.toArray()\n",
    "print(\"Feature Importances: \",featureImportances)\n",
    "    \n",
    "predictions = fitModel.transform(test)\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(\" \")\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create all encompassing Classification Training and Evaluation Function\n",
    "This function also us to iterativley pass through any classifier and train and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassTrainEval(classifier,features,classes,train,test):\n",
    "\n",
    "    def FindMtype(classifier):\n",
    "        # Intstantiate Model\n",
    "        M = classifier\n",
    "        # Learn what it is\n",
    "        Mtype = type(M).__name__\n",
    "        \n",
    "        return Mtype\n",
    "    \n",
    "    Mtype = FindMtype(classifier)\n",
    "    \n",
    "\n",
    "    def IntanceFitModel(Mtype,classifier,classes,features,train):\n",
    "        \n",
    "        if Mtype == \"OneVsRest\":\n",
    "            # instantiate the base classifier.\n",
    "            lr = LogisticRegression()\n",
    "            # instantiate the One Vs Rest Classifier.\n",
    "            OVRclassifier = OneVsRest(classifier=lr)\n",
    "#             fitModel = OVRclassifier.fit(train)\n",
    "            # Add parameters of your choice here:\n",
    "            paramGrid = ParamGridBuilder() \\\n",
    "                .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "                .build()\n",
    "            #Cross Validator requires the following parameters:\n",
    "            crossval = CrossValidator(estimator=OVRclassifier,\n",
    "                                      estimatorParamMaps=paramGrid,\n",
    "                                      evaluator=MulticlassClassificationEvaluator(),\n",
    "                                      numFolds=2) # 3 is best practice\n",
    "            # Run cross-validation, and choose the best set of parameters.\n",
    "            fitModel = crossval.fit(train)\n",
    "            return fitModel\n",
    "        if Mtype == \"MultilayerPerceptronClassifier\":\n",
    "            # specify layers for the neural network:\n",
    "            # input layer of size features, two intermediate of features+1 and same size as features\n",
    "            # and output of size number of classes\n",
    "            # Note: crossvalidator cannot be used here\n",
    "            features_count = len(features[0][0])\n",
    "            layers = [features_count, features_count+1, features_count, classes]\n",
    "            MPC_classifier = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "            fitModel = MPC_classifier.fit(train)\n",
    "            return fitModel\n",
    "        if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2: # These classifiers currently only accept binary classification\n",
    "            print(Mtype,\" could not be used because PySpark currently only accepts binary classification data for this algorithm\")\n",
    "            return\n",
    "        if Mtype in(\"LogisticRegression\",\"NaiveBayes\",\"RandomForestClassifier\",\"GBTClassifier\",\"LinearSVC\",\"DecisionTreeClassifier\"):\n",
    "  \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"LogisticRegression\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
    "                             .addGrid(classifier.maxIter, [10, 15,20])\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"NaiveBayes\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "                             .addGrid(classifier.smoothing, [0.0, 0.2, 0.4, 0.6]) \\\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"RandomForestClassifier\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "                               .addGrid(classifier.maxDepth, [2, 5, 10])\n",
    "#                                .addGrid(classifier.maxBins, [5, 10, 20])\n",
    "#                                .addGrid(classifier.numTrees, [5, 20, 50])\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"GBTClassifier\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "#                              .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "                             .addGrid(classifier.maxIter, [10, 15,50,100])\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"LinearSVC\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "                             .addGrid(classifier.maxIter, [10, 15]) \\\n",
    "                             .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
    "                             .build())\n",
    "            \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"DecisionTreeClassifier\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "                             .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "                             .build())\n",
    "            \n",
    "            #Cross Validator requires all of the following parameters:\n",
    "            crossval = CrossValidator(estimator=classifier,\n",
    "                                      estimatorParamMaps=paramGrid,\n",
    "                                      evaluator=MulticlassClassificationEvaluator(),\n",
    "                                      numFolds=2) # 3 + is best practice\n",
    "            # Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "            fitModel = crossval.fit(train)\n",
    "            return fitModel\n",
    "    \n",
    "    fitModel = IntanceFitModel(Mtype,classifier,classes,features,train)\n",
    "    \n",
    "    # Print feature selection metrics\n",
    "    if fitModel is not None:\n",
    "        \n",
    "        if Mtype in(\"OneVsRest\"):\n",
    "            # Get Best Model\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype + '\\033[0m')\n",
    "            # Extract list of binary models\n",
    "            models = BestModel.models\n",
    "            for model in models:\n",
    "                print('\\033[1m' + 'Intercept: '+ '\\033[0m',model.intercept,'\\033[1m' + '\\nCoefficients:'+ '\\033[0m',model.coefficients)\n",
    "\n",
    "        if Mtype == \"MultilayerPerceptronClassifier\":\n",
    "            print(\"\")\n",
    "            print('\\033[1m' + Mtype,\" Weights\"+ '\\033[0m')\n",
    "            print('\\033[1m' + \"Model Weights: \"+ '\\033[0m',fitModel.weights.size)\n",
    "            print(\"\")\n",
    "\n",
    "        if Mtype in(\"DecisionTreeClassifier\", \"GBTClassifier\",\"RandomForestClassifier\"):\n",
    "            # FEATURE IMPORTANCES\n",
    "            # Estimate of the importance of each feature.\n",
    "            # Each features importance is the average of its importance across all trees \n",
    "            # in the ensemble The importance vector is normalized to sum to 1. \n",
    "            # Get Best Model\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype,\" Feature Importances\"+ '\\033[0m')\n",
    "            print(\"(Scores add up to 1)\")\n",
    "            print(\"Lowest score is the least important\")\n",
    "            print(\" \")\n",
    "            print(BestModel.featureImportances)\n",
    "            \n",
    "            if Mtype in(\"DecisionTreeClassifier\"):\n",
    "                global DT_featureimportances\n",
    "                DT_featureimportances = BestModel.featureImportances.toArray()\n",
    "                global DT_BestModel\n",
    "                DT_BestModel = BestModel\n",
    "            if Mtype in(\"GBTClassifier\"):\n",
    "                global GBT_featureimportances\n",
    "                GBT_featureimportances = BestModel.featureImportances.toArray()\n",
    "                global GBT_BestModel\n",
    "                GBT_BestModel = BestModel\n",
    "            if Mtype in(\"RandomForestClassifier\"):\n",
    "                global RF_featureimportances\n",
    "                RF_featureimportances = BestModel.featureImportances.toArray()\n",
    "                global RF_BestModel\n",
    "                RF_BestModel = BestModel\n",
    "\n",
    "        if Mtype in(\"LogisticRegression\"):\n",
    "            # Get Best Model\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype,\" Coefficient Matrix\"+ '\\033[0m')\n",
    "            print(\"You should compares these relative to eachother\")\n",
    "            print(\"Coefficients: \\n\" + str(BestModel.coefficientMatrix))\n",
    "            print(\"Intercept: \" + str(BestModel.interceptVector))\n",
    "            global LR_coefficients\n",
    "            LR_coefficients = BestModel.coefficientMatrix.toArray()\n",
    "            global LR_BestModel\n",
    "            LR_BestModel = BestModel\n",
    "\n",
    "        if Mtype in(\"LinearSVC\"):\n",
    "            # Get Best Model\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype,\" Coefficients\"+ '\\033[0m')\n",
    "            print(\"You should compares these relative to eachother\")\n",
    "            print(\"Coefficients: \\n\" + str(BestModel.coefficients))\n",
    "            global LSVC_coefficients\n",
    "            LSVC_coefficients = BestModel.coefficients.toArray()\n",
    "            global LSVC_BestModel\n",
    "            LSVC_BestModel = BestModel\n",
    "        \n",
    "   \n",
    "    # Set the column names to match the external results dataframe that we will join with later:\n",
    "    columns = ['Classifier', 'Result']\n",
    "    \n",
    "    if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2:\n",
    "        Mtype = [Mtype] # make this a list\n",
    "        score = [\"N/A\"]\n",
    "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
    "    else:\n",
    "        predictions = fitModel.transform(test)\n",
    "        MC_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\") # redictionCol=\"prediction\",\n",
    "        accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "        Mtype = [Mtype] # make this a string\n",
    "        score = [str(accuracy)] #make this a string and convert to a list\n",
    "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
    "        result = result.withColumn('Result',result.Result.substr(0, 5))\n",
    "        \n",
    "    return result\n",
    "    #Also returns the fit model important scores or p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.classification import *\n",
    "# from pyspark.ml.evaluation import *\n",
    "# from pyspark.sql import functions\n",
    "# from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Comment out Naive Bayes if your data still contains negative values\n",
    "classifiers = [\n",
    "                LogisticRegression()\n",
    "                ,OneVsRest()\n",
    "               ,LinearSVC()\n",
    "               ,NaiveBayes()\n",
    "               ,RandomForestClassifier()\n",
    "               ,GBTClassifier()\n",
    "               ,DecisionTreeClassifier()\n",
    "               ,MultilayerPerceptronClassifier()\n",
    "              ] \n",
    "\n",
    "featureDF_list = [HTFfeaturizedData,TFIDFfeaturizedData,W2VfeaturizedData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mHTFfeaturizedData  Results:\u001b[0m\n",
      " \n",
      "\u001b[1mLogisticRegression  Coefficient Matrix\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "DenseMatrix([[-0.03887312, -0.03588526,  0.07307599, -0.00198963,  0.05241345,\n",
      "               0.01283564,  0.01537288,  0.00417559, -0.04219799, -0.02513613,\n",
      "               0.00393539,  0.00339796,  0.04777044, -0.06073248, -0.00429448,\n",
      "               0.01497416,  0.00661035, -0.01435145,  0.0770096 , -0.01242766]])\n",
      "Intercept: [-1.74414154586384]\n",
      " \n",
      "\u001b[1mOneVsRest\u001b[0m\n",
      "\u001b[1mIntercept: \u001b[0m 1.7410187222960556 \u001b[1m\n",
      "Coefficients:\u001b[0m [0.01437586840641003,0.013219286777314378,-0.03149779225069064,-0.0008909001576969105,-0.02286012542393386,-0.007824434469452527,-0.006936977761607128,-0.004861400745946295,0.012882752354334281,0.009717501838771715,-0.003178312131499693,-0.003971385389827328,-0.020723763421755022,0.01991574970435164,0.0005112888789387337,-0.005562972670953192,-0.0032714604963370894,0.0023937420915032346,-0.033411768973834716,0.0028468345143323817]\n",
      "\u001b[1mIntercept: \u001b[0m -1.7410187222960556 \u001b[1m\n",
      "Coefficients:\u001b[0m [-0.01437586840641004,-0.01321928677731438,0.031497792250690645,0.0008909001576969063,0.022860125423933866,0.007824434469452529,0.006936977761607132,0.004861400745946298,-0.012882752354334288,-0.009717501838771715,0.003178312131499696,0.003971385389827332,0.020723763421755022,-0.019915749704351643,-0.0005112888789387418,0.005562972670953195,0.0032714604963370916,-0.002393742091503234,0.033411768973834716,-0.0028468345143323843]\n",
      " \n",
      "\u001b[1mLinearSVC  Coefficients\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "[-0.0002600700619837618,-0.00015156968255712104,0.0015799397263439215,0.0,0.0020615137509956433,-0.00014209697961850397,-0.00036725986786926803,-0.0008172531142213443,-0.0012366722589324235,0.0,0.0,-0.00034957824145547586,0.0013043665963285477,-0.0008990617872469476,0.0,0.0,-0.00023045491319133285,0.0,0.0015834952510773517,0.0]\n",
      " \n",
      "\u001b[1mRandomForestClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.05825338192965546,0.04326702719860378,0.07506559504740945,0.040092229140531885,0.058995639733072744,0.041933291534098985,0.04774308175799942,0.04514501136886247,0.04535508467915221,0.04514796602987151,0.05524737304231715,0.04213597569540262,0.060429730112381806,0.04895631484938151,0.04719002494673596,0.059023612376742515,0.046029403366631375,0.03837230325144898,0.06406103971937105,0.0375559142203291])\n",
      " \n",
      "\u001b[1mGBTClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.05755831582989645,0.03604662957437776,0.061259286351320434,0.04553499682866607,0.06401338523803529,0.0371093463113751,0.05975467886843379,0.05253696133806693,0.05771691373667694,0.048670486963921365,0.042420036255050586,0.03771631081968787,0.06022911290231446,0.052095414837088926,0.04417379113473291,0.052856644468188656,0.05403066196931306,0.04618248327553763,0.054092968031414494,0.03600157526590132])\n",
      " \n",
      "\u001b[1mDecisionTreeClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(20,[0,1,2,4,10,12,13,15,18,19],[0.03632251692387909,0.05941145455966606,0.22393781439006258,0.06720538795293181,0.021640790893683422,0.0408427310555562,0.0776988429069132,0.05806598326632612,0.39137654901845526,0.023497929032526274])\n",
      "\n",
      "\u001b[1mMultilayerPerceptronClassifier  Weights\u001b[0m\n",
      "\u001b[1mModel Weights: \u001b[0m 923\n",
      "\n",
      "+------------------------------+------+\n",
      "|Classifier                    |Result|\n",
      "+------------------------------+------+\n",
      "|LogisticRegression            |83.90 |\n",
      "|OneVsRest                     |83.92 |\n",
      "|LinearSVC                     |83.95 |\n",
      "|NaiveBayes                    |83.82 |\n",
      "|RandomForestClassifier        |84.04 |\n",
      "|GBTClassifier                 |83.76 |\n",
      "|DecisionTreeClassifier        |83.86 |\n",
      "|MultilayerPerceptronClassifier|83.90 |\n",
      "+------------------------------+------+\n",
      "\n",
      "None\n",
      "\u001b[1mTFIDFfeaturizedData  Results:\u001b[0m\n",
      " \n",
      "\u001b[1mLogisticRegression  Coefficient Matrix\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "DenseMatrix([[-0.1520614 , -0.08198034,  0.18959737, -0.00812837,  0.13706335,\n",
      "               0.03131677,  0.06161149,  0.01308424, -0.14350668, -0.06389487,\n",
      "               0.02451638,  0.00751358,  0.16813763, -0.20315584, -0.01067561,\n",
      "               0.04568327,  0.01675017, -0.04665017,  0.17661641, -0.02434286]])\n",
      "Intercept: [-1.7441415458638398]\n",
      " \n",
      "\u001b[1mOneVsRest\u001b[0m\n",
      "\u001b[1mIntercept: \u001b[0m 1.7410187222960556 \u001b[1m\n",
      "Coefficients:\u001b[0m [0.05623461447543104,0.03019963151426085,-0.08172176503426175,-0.0036396570676845,-0.05978017927051304,-0.019090282930701537,-0.027802047824017802,-0.01523322312032963,0.04381158886848305,0.02470143907261942,-0.019799986171053437,-0.008781543417656357,-0.07294143400307082,0.06662005408350023,0.0012710085337233178,-0.016971556954611926,-0.00828965239134729,0.007780986795744571,-0.07662767964751792,0.005576280858245069]\n",
      "\u001b[1mIntercept: \u001b[0m -1.7410187222960556 \u001b[1m\n",
      "Coefficients:\u001b[0m [-0.056234614475431044,-0.030199631514260833,0.08172176503426172,0.0036396570676844797,0.05978017927051303,0.01909028293070153,0.02780204782401778,0.015233223120329627,-0.04381158886848307,-0.02470143907261943,0.019799986171053423,0.008781543417656364,0.07294143400307085,-0.06662005408350023,-0.001271008533723299,0.01697155695461193,0.008289652391347296,-0.007780986795744585,0.07662767964751792,-0.005576280858245062]\n",
      " \n",
      "\u001b[1mLinearSVC  Coefficients\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "[-0.0010173256500966893,-0.0003462628989797861,0.004099190891124788,0.0,0.005390944245393517,-0.00034669234627853173,-0.0014719055994175513,-0.0025608666483832045,-0.004205667786137134,0.0,0.0,-0.0007729888197383682,0.004590979353781063,-0.0030074461559296377,0.0,0.0,-0.0005839566531137165,0.0,0.00363164150087238,0.0]\n",
      " \n",
      "\u001b[1mRandomForestClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.05825338192965546,0.04326702719860378,0.07506559504740945,0.040092229140531885,0.058995639733072744,0.041933291534098985,0.04774308175799942,0.04514501136886247,0.04535508467915221,0.04514796602987151,0.05524737304231715,0.04213597569540262,0.060429730112381806,0.04895631484938151,0.04719002494673596,0.059023612376742515,0.046029403366631375,0.03837230325144898,0.06406103971937105,0.0375559142203291])\n",
      " \n",
      "\u001b[1mGBTClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.053973623099824904,0.03812330302476772,0.054446614592636444,0.048363954433714426,0.06509048877072103,0.04545025959092503,0.06257755120345894,0.04465153205077919,0.051441154788688284,0.04924064217060297,0.052414674055409755,0.034711352190145144,0.06483964697063778,0.051771772882099276,0.04782955527534325,0.046865792704334684,0.050176055223000546,0.04587105614094324,0.056349114425065995,0.035811856406901404])\n",
      " \n",
      "\u001b[1mDecisionTreeClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(20,[0,1,2,4,10,12,13,15,18,19],[0.03632251692387909,0.05941145455966606,0.22393781439006258,0.06720538795293181,0.021640790893683422,0.0408427310555562,0.0776988429069132,0.05806598326632612,0.39137654901845526,0.023497929032526274])\n",
      "\n",
      "\u001b[1mMultilayerPerceptronClassifier  Weights\u001b[0m\n",
      "\u001b[1mModel Weights: \u001b[0m 923\n",
      "\n",
      "+------------------------------+------+\n",
      "|Classifier                    |Result|\n",
      "+------------------------------+------+\n",
      "|LogisticRegression            |83.90 |\n",
      "|OneVsRest                     |83.92 |\n",
      "|LinearSVC                     |83.95 |\n",
      "|NaiveBayes                    |83.95 |\n",
      "|RandomForestClassifier        |84.04 |\n",
      "|GBTClassifier                 |83.78 |\n",
      "|DecisionTreeClassifier        |83.86 |\n",
      "|MultilayerPerceptronClassifier|83.94 |\n",
      "+------------------------------+------+\n",
      "\n",
      "None\n",
      "\u001b[1mW2VfeaturizedData  Results:\u001b[0m\n",
      " \n",
      "\u001b[1mLogisticRegression  Coefficient Matrix\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "DenseMatrix([[-9.89021276, 12.35573549, 11.01829685]])\n",
      "\n",
      "Intercept: [-8.497016764794573]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mOneVsRest\u001b[0m\n",
      "\u001b[1mIntercept: \u001b[0m 1.4726702019506157 \u001b[1m\n",
      "Coefficients:\u001b[0m [1.4013113811736666,-0.8577465187768131,-0.18734253482253893]\n",
      "\u001b[1mIntercept: \u001b[0m -1.4726702019506153 \u001b[1m\n",
      "Coefficients:\u001b[0m [-1.4013113811736666,0.8577465187768131,0.18734253482253832]\n",
      " \n",
      "\u001b[1mLinearSVC  Coefficients\u001b[0m\n",
      "You should compares these relative to eachother\n",
      "Coefficients: \n",
      "[-0.14136597442183704,0.19527600763891134,0.18528475579148718]\n",
      " \n",
      "\u001b[1mRandomForestClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(3,[0,1,2],[0.3375748086933921,0.3656097920289301,0.2968153992776778])\n",
      " \n",
      "\u001b[1mGBTClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(3,[0,1,2],[0.3376577025241064,0.321911701330617,0.34043059614527665])\n",
      " \n",
      "\u001b[1mDecisionTreeClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(3,[],[])\n",
      "\n",
      "\u001b[1mMultilayerPerceptronClassifier  Weights\u001b[0m\n",
      "\u001b[1mModel Weights: \u001b[0m 39\n",
      "\n",
      "+------------------------------+------+\n",
      "|Classifier                    |Result|\n",
      "+------------------------------+------+\n",
      "|LogisticRegression            |83.90 |\n",
      "|OneVsRest                     |83.95 |\n",
      "|LinearSVC                     |83.95 |\n",
      "|NaiveBayes                    |83.95 |\n",
      "|RandomForestClassifier        |83.96 |\n",
      "|GBTClassifier                 |84.06 |\n",
      "|DecisionTreeClassifier        |83.95 |\n",
      "|MultilayerPerceptronClassifier|83.95 |\n",
      "+------------------------------+------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for featureDF in featureDF_list:\n",
    "    print('\\033[1m' + featureDF.name,\" Results:\"+ '\\033[0m')\n",
    "    train, test = featureDF.randomSplit([0.7, 0.3],seed = 11)\n",
    "    features = featureDF.select(['features']).collect()\n",
    "    # Learn how many classes there are in order to specify evaluation type based on binary or multi and turn the df into an object\n",
    "    class_count = featureDF.select(countDistinct(\"label\")).collect()\n",
    "    classes = class_count[0][0]\n",
    "\n",
    "    #set up your results table\n",
    "    columns = ['Classifier', 'Result']\n",
    "    vals = [(\"Place Holder\",\"N/A\")]\n",
    "    results = spark.createDataFrame(vals, columns)\n",
    "\n",
    "    for classifier in classifiers:\n",
    "        new_result = ClassTrainEval(classifier,features,classes,train,test)\n",
    "        results = results.union(new_result)\n",
    "    results = results.where(\"Classifier!='Place Holder'\")\n",
    "    print(results.show(truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
